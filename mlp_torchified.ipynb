{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed518596-02c8-494a-a171-1523fefaeb8c",
   "metadata": {},
   "source": [
    "### building data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26bc30b1-fe36-43fe-9801-af009a7cf481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_words = open('names.txt', 'r').read().splitlines()\n",
    "\n",
    "chars = sorted(list(set(''.join(all_words))))\n",
    "ctoi = {c:i+1 for i, c in enumerate(chars)}\n",
    "ctoi['.'] = 0\n",
    "itoc = {i:c for c, i in ctoi.items()}\n",
    "\n",
    "CONTEXT_WINDOW =4\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "\n",
    "        context = [0] * CONTEXT_WINDOW\n",
    "        #print(w)\n",
    "        for ch in w + '.':\n",
    "            ix = ctoi[ch]\n",
    "            Y.append(ix)\n",
    "            X.append(context)\n",
    "            #print(''.join(itoc[po] for po in context), '--->', ch)\n",
    "            context = context[1:] + [ix]\n",
    "            \n",
    "    return (X, Y)\n",
    "\n",
    "import random\n",
    "random.shuffle(all_words)\n",
    "\n",
    "L1 = int(0.8*len(all_words))\n",
    "L2 = L1 + int(0.1*len(all_words))\n",
    "\n",
    "X_train, Y_train = build_dataset(all_words[:L1])\n",
    "X_val, Y_val = build_dataset(all_words[L1:L2])\n",
    "X_test, Y_test = build_dataset(all_words[L2:])\n",
    "\n",
    "X_train = torch.tensor(X_train)\n",
    "Y_train = torch.tensor(Y_train)\n",
    "X_val = torch.tensor(X_val)\n",
    "Y_val = torch.tensor(Y_val)\n",
    "X_test = torch.tensor(X_test)\n",
    "Y_test = torch.tensor(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed03ebb-a485-4a00-944d-254bc29137b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Linear:\n",
    "    \n",
    "    def __init__ (self, fanin, fanout, bias=True):\n",
    "        self.W = torch.randn((fanin, fanout)) * ((2/fanin) ** 0.5)\n",
    "        self.b = torch.zeros(fanout) if bias else None\n",
    "        self.bias = bias\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        self.out = X @ self.W\n",
    "        if self.bias is not None:\n",
    "            self.out += self.b\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.W] + [self.b if self.bias else None]\n",
    "    \n",
    "    \n",
    "class ReLU:\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        self.out = torch.relu(X)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class BatchNorm1D:\n",
    "    \n",
    "    def __init__(self, dim, momentum=.1, eps=1e-5):\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        self.training = True\n",
    "        \n",
    "        self.momentum = momentum\n",
    "        self.eps = eps ** 0.5\n",
    "        \n",
    "        self.running_std = torch.zeros(0)\n",
    "        self.running_mean = torch.zeros(0)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma] + [self.beta]\n",
    "        \n",
    "    def __call__(self, X):\n",
    "        if self.training:\n",
    "            mean = X.mean(0, keepdim=True)\n",
    "            std = X.std(0, keepdim=True)\n",
    "            with torch.no_grad():\n",
    "                self.running_std = (1-self.momentum) * self.running_std + self.momentum * std\n",
    "                self.running_mean = (1-self.momentum) * self.running_mean + self.momentum * mean\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "            std = self.running_std\n",
    "        self.out = self.gamma * ((X-mean) / std + self.eps) + self.beta\n",
    "        return self.out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9651b9b3-b0e4-4509-b536-6abf27d08b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONTEXT = 4\n",
    "WORDVEC = 15\n",
    "NIN = CONTEXT * WORDVEC\n",
    "HIDDEN = 200\n",
    "\n",
    "C = torch.randn(27, WORDVEC) #character embeddings\n",
    "model = [\n",
    "    Linear(NIN, HIDDEN), BatchNorm1D(HIDDEN), ReLU(),\n",
    "    Linear(HIDDEN, HIDDEN), BatchNorm1D(HIDDEN), ReLU(),\n",
    "    Linear(HIDDEN, HIDDEN), BatchNorm1D(HIDDEN), ReLU(),\n",
    "    Linear(HIDDEN, HIDDEN),\n",
    "]\n",
    "\n",
    "parameters = [C] + [p for layer in model for p in layer.parameters()]\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874ef6e-9de8-4548-9221-7c254883278f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0774b41-4664-491e-b3f0-55aaeb5775ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 1\n",
    "BATCH_SIZE = 32\n",
    "train_losses = []\n",
    "train_steps = []\n",
    "val_losses = []\n",
    "val_steps = []\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    ix = torch.randint(0, X_train.shape[0], (BATCH_SIZE, ))\n",
    "    enc = C[X_train[ix]].view(BATCH_SIZE, -1)\n",
    "    \n",
    "    pred = enc\n",
    "    for layer in model:\n",
    "        pred = layer(pred)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755cc265-7fe5-40c1-837d-53efc688641c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
